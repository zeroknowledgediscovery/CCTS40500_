{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flexroc(fname):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    FLEXROC = '/home/yhuang10/Spatio-Temporal/cynet_/bin/flexroc '\n",
    "    \n",
    "    RES = {}\n",
    "    \n",
    "    h = np.array(fname.split('/')[-1].split('_')[0].split('#')).astype(float)\n",
    "    RES['lat1'], RES['lat2'], RES['lon1'], RES['lon2'] = h \n",
    "    df = pd.read_csv(fname)\n",
    "\n",
    "    df[['AR_grt','AR_prd']].to_csv('tmp.csv', header=None, index=None, sep=' ')\n",
    "\n",
    "    result = ! $FLEXROC -i tmp.csv -w 1 -x 0 -t 0.8 -f 0.2 -E 0 -C 1 -L 1\n",
    "    RES['VAR'] = float(result[0].split()[1])\n",
    "    \n",
    "    df[['AS_grt','AS_prd']].to_csv('tmp.csv', header=None, index=None, sep=' ')\n",
    "    result = ! $FLEXROC -i tmp.csv -w 1 -x 0 -t 0.8 -f 0.2 -E 0 -C 1 -L 1\n",
    "    RES['HOMICIDE-ASSAULT-BATTERY'] = float(result[0].split()[1])\n",
    "    \n",
    "    df[['PR_grt','PR_prd']].to_csv('tmp.csv',header=None,index=None,sep=' ')\n",
    "    result = ! $FLEXROC -i tmp.csv -w 1 -x 0 -t 0.8 -f 0.2 -E 0 -C 1 -L 1\n",
    "    RES['BURGLARY-THEFT-MOTOR_VEHICLE_THEFT'] = float(result[0].split()[1])\n",
    "    \n",
    "    ! rm tmp.csv\n",
    "    \n",
    "    return RES\n",
    "\n",
    "RES = flexroc('./results/random_100-10_100/41.73216#41.73492#-87.55528000000002#-87.55176_1.rnnres') \n",
    "RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv('meta.csv', index_col=0)\n",
    "X_raw = np.genfromtxt('CRIME-_2014-01-01_2016-12-31.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cynetTop = [\n",
    "    '41.8828#-87.7435', '41.7584#-87.6555', \n",
    "    '41.8828#-87.6274', '41.7750#-87.6520', \n",
    "    '41.9104#-87.7048', '41.7446#-87.6520',\n",
    "    '41.9270#-87.7364', '41.7833#-87.5957', \n",
    "    '41.9823#-87.6555', '41.8275#-87.6168'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrest: 1293,\n",
      "Property: 3632,\n",
      "Assault: 5673.\n",
      "Training data: input dim = (1, 727, 6165), output dim = (1, 727, 3)\n",
      "Out-sample data: input dim = (1, 366, 6165), output dim = (1, 366, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 50)          1243200   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 10)          2440      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 10)          840       \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 3)           33        \n",
      "=================================================================\n",
      "Total params: 1,246,513\n",
      "Trainable params: 1,246,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.2893\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2211\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2060\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1962\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1892\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1840\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1804\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1778\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1755\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1734\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1714\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1695\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1677\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1660\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1643\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1628\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1614\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1600\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1587\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.1575\n"
     ]
    }
   ],
   "source": [
    "center = cynetTop[0]\n",
    "tile = meta.loc[center, ['lat1', 'lat2','lon1', 'lon2']]\n",
    "    \n",
    "future = 3\n",
    "    \n",
    "X_train, Y_train, X_test, Y_test = rnn.getData(meta, X_raw, center, future)\n",
    "\n",
    "model = rnn.train_3(X_train, Y_train, epochs=20)\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figTitle = '#'.join(map(str, tile.values)) + '_{}'.format(future)\n",
    "dfName = figTitle + '.rnnres'\n",
    "rnn.Analysis(Y_test, prediction, figTitle, dfName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 comparison:\n",
    "Test the performance of (deep) RNN with horizon=$7$ on the ten blocks\n",
    "on which cynet got the higest average AUC scores for the 3 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "future = 7\n",
    "RES = []\n",
    "for center in cynetTop:\n",
    "    tile = meta.loc[center, ['lat1', 'lat2','lon1', 'lon2']]\n",
    "\n",
    "    X_train, Y_train, X_test, Y_test = rnn.getData(meta, X_raw, center, future)\n",
    "\n",
    "    model = rnn.train_3(X_train, Y_train, epochs=20)\n",
    "    prediction = model.predict(X_test)\n",
    "    \n",
    "    figTitle = '#'.join(map(str, tile.values)) + '_{}'.format(future)\n",
    "    dfName = 'results/top10_deeper/' + figTitle + '.rnnres'\n",
    "    rnn.Analysis(Y_test, prediction, figTitle, dfName)\n",
    "    rnnres = flexroc(dfName)\n",
    "    RES.append(rnnres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cynet = pd.read_csv('../data/cynet_performance.csv').round(4)\n",
    "rnn = pd.DataFrame(data=RES)\n",
    "rnn = rnn.set_index(['lat1','lat2','lon1','lon2']).stack().reset_index().rename(columns={'level_4':'var',0:'auc_NN'}).round(4)\n",
    "df = cynet.set_index(['lat1','lat2','lon1','lon2','var']).join(rnn.set_index(['lat1','lat2','lon1','lon2','var'])).reset_index().dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.auc)\n",
    "sns.distplot(df.auc_NN)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Performance:\n",
    "Test the performance of (deep) RNN with horizon=$7$ on the $50$ blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = [ \n",
    "    298, 304, 908, 1176, 453,  \n",
    "    281, 947, 203, 1443, 159,  \n",
    "    870, 109, 103, 1206, 1084, \n",
    "    615, 1013, 324, 470, 901,\n",
    "    1025, 260, 1106, 551, 82, \n",
    "    903, 1137, 1477, 210, 388,\n",
    "    824, 270,  595, 269, 454,\n",
    "    291, 637, 930, 292, 360,\n",
    "    832, 29, 320, 498, 1181, \n",
    "    1352, 732, 1164, 488, 1124\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
